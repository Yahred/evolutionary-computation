{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yahred/evolutionary-computation/blob/main/EvolucionAlgorimoConvLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBAOAz4QeY6T"
      },
      "outputs": [],
      "source": [
        "%pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj2mN70-ao4t"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZAa8q8JFPbc"
      },
      "source": [
        "* Número de filtros en las capas ConvLSTM2D:\n",
        "\n",
        "Para la primera y segunda capa: 16 (puede ser cualquier entero positivo).\n",
        "Para la tercera capa: también 16 (puede ser cualquier entero positivo).\n",
        "\n",
        "* Tamaño del kernel en las capas ConvLSTM2D:\n",
        "\n",
        "Para la primera y segunda capa: (5,5) (puede ser cualquier par de enteros positivos).\n",
        "Para la tercera capa: (3,3) (puede ser cualquier par de enteros positivos).\n",
        "* Activación en las capas ConvLSTM2D y Conv2D:\n",
        "\n",
        "relu para las capas ConvLSTM2D.\n",
        "sigmoid para la capa Conv2D.\n",
        "Podrían ser 'tanh', 'softmax', etc.\n",
        "* Número de canales (channels) en la capa Conv2D:\n",
        "\n",
        "Depende de tu tarea específica (por ejemplo, 1 para la segmentación binaria, 3 para imágenes RGB).\n",
        "* Función de pérdida al compilar el modelo:\n",
        "\n",
        "binary_crossentropy en este ejemplo.\n",
        "Podrías elegir 'categorical_crossentropy', 'mean_squared_error', etc.\n",
        "* Optimizador al compilar el modelo:\n",
        "\n",
        "Adam en este ejemplo.\n",
        "Podrías elegir 'SGD', 'RMSprop', etc., y también sus hiperparámetros asociados.\n",
        "* patience para EarlyStopping:\n",
        "\n",
        "6 en este ejemplo.\n",
        "Puede ser cualquier entero positivo.\n",
        "* restore_best_weights para EarlyStopping:\n",
        "\n",
        "True en este ejemplo.\n",
        "Puede ser True o False.\n",
        "* patience para ReduceLROnPlateau:\n",
        "\n",
        "4 en este ejemplo.\n",
        "Puede ser cualquier entero positivo.\n",
        "* Epochs:\n",
        "\n",
        "20 en este ejemplo.\n",
        "Puede ser cualquier entero positivo.\n",
        "* Batch size:\n",
        "\n",
        "1 en este ejemplo.\n",
        "Puede ser cualquier entero positivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fuwvf9ZQbBqN"
      },
      "source": [
        "## Librerias y cargar dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hq2EqjYM2kcz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "from urllib.request import urlopen\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se descarga el dataset por medio de una petición HTTP y se extrae\n"
      ],
      "metadata": {
        "id": "FJncZlbIx_kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/Yahred/evolutionary-computation/raw/main/data/DroughtDatasetMask.zip'\n",
        "response = requests.get(url)\n",
        "data = None\n",
        "\n",
        "if response.status_code != 200:\n",
        "  display(HTML((response.text)))\n",
        "else:\n",
        "  zip_file = io.BytesIO(response.content)\n",
        "  data = zipfile.ZipFile(zip_file, 'r')\n",
        "  data.extractall()"
      ],
      "metadata": {
        "id": "YRX-mfgJugHt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNr4xFjnGHRJ"
      },
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4EBDpQpZGTpv"
      },
      "outputs": [],
      "source": [
        "def create_shifted_frames_2(data):\n",
        "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
        "    y = data[:, data.shape[1]-1, :, :]\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "s3_pJVteGUFU"
      },
      "outputs": [],
      "source": [
        "#Toma todos los colores existentes en la imagen\n",
        "def get_colors(image):\n",
        "  aux = []\n",
        "  band = True\n",
        "  for i in image:\n",
        "    for j in i:\n",
        "\n",
        "      for k in aux:\n",
        "        if j.tolist() == k:\n",
        "          band = False\n",
        "          break\n",
        "      if band:\n",
        "        aux.append(j.tolist())\n",
        "      band = True\n",
        "  return np.array(aux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "j1G3jCDrGWN7"
      },
      "outputs": [],
      "source": [
        "def balance_img_categories(img, palette, balancer):\n",
        "  #palette = np.sort(palette)\n",
        "  rows = len(img)\n",
        "  cols = len(img[0])\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      pos = np.where(palette == img[i,j])[0][0]\n",
        "      img[i,j] = balancer[pos]\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MIROb6RBGZML"
      },
      "outputs": [],
      "source": [
        "#Función para dada una paleta solo tomar los colores de esa paleta en la imagen\n",
        "def quantizetopalette(silf, palette, dither=False, mode=\"P\"):\n",
        "  \"\"\"Convert an RGB or L mode image to use a given P image's palette.\"\"\"\n",
        "  silf.load()\n",
        "  palette.load()\n",
        "  im = silf.im.convert(mode, 0, palette.im)\n",
        "  # the 0 above means turn OFF dithering making solid colors\n",
        "  return silf._new(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hcM1PYj9Ga99"
      },
      "outputs": [],
      "source": [
        "#Realiza las operaciones necesarias para obtener una imagen RGB por una paleta de colores\n",
        "def rgb_quantized(img, palette):\n",
        "  rows, cols = len(img), len(img[0])\n",
        "  total_vals = 1\n",
        "  for i in palette.shape:\n",
        "    total_vals *= i\n",
        "  palettedata = palette.reshape(total_vals).tolist()\n",
        "  palImage = Image.new('P', (rows, cols))\n",
        "  palImage.putpalette(palettedata*32)\n",
        "  oldImage = Image.fromarray(img).convert(\"RGB\")\n",
        "  newImage = quantizetopalette(oldImage,palImage)\n",
        "  res_image = np.asarray(newImage.convert(\"RGB\"))\n",
        "  return res_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "a3jqk96wGcX1"
      },
      "outputs": [],
      "source": [
        "def gray_quantized(img, palette):\n",
        "  rows, cols = len(img), len(img[0])\n",
        "  total_vals = 1\n",
        "  for i in palette.shape:\n",
        "    total_vals *= i\n",
        "  palettedata = palette.reshape(total_vals).tolist()\n",
        "  palImage = Image.new('L', (rows, cols))\n",
        "  palImage.putpalette(palettedata*32)\n",
        "  oldImage = Image.fromarray(img, 'L')\n",
        "  newImage = quantizetopalette(oldImage,palImage, mode=\"L\")\n",
        "  res_image = np.asarray(newImage)\n",
        "  return res_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "p1y6vWRJGdlb"
      },
      "outputs": [],
      "source": [
        "def recolor_greys_image(data, palette):\n",
        "    rows, cols = len(data), len(data[0])\n",
        "    aux = np.zeros((rows, cols), dtype=np.uint64)\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            aux[i,j] = min(palette, key= lambda x:abs(x-data[i,j]))\n",
        "    return aux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ec1Q5aXoGetT"
      },
      "outputs": [],
      "source": [
        "def agroup_window(data, window):\n",
        "    new_data = [data[i:window+i] for i in range(len(data)-window+1)]\n",
        "    return np.array(new_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "J21867-jGgAL"
      },
      "outputs": [],
      "source": [
        "def add_last(data, new_vals):\n",
        "    print(f\"data: {data.shape} y new_val: {new_vals.shape}\")\n",
        "    x_test_new = data[:,1:]\n",
        "    print(f\"x_test_new: {x_test_new.shape}\")\n",
        "\n",
        "    l = []\n",
        "    for i in range(len(x_test_new)):\n",
        "        l.append(np.append(x_test_new[i], new_vals[i]))\n",
        "    x_test_new = np.array(l).reshape(data.shape[:])\n",
        "    print(\"CX\", x_test_new.shape)\n",
        "    return x_test_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1ZaQ_edXGhMr"
      },
      "outputs": [],
      "source": [
        "def add_lastNew(data, new_val):\n",
        "    print(f\"data: {data.shape} y new_val: {new_val.shape}\")\n",
        "    x_test_new = data[:,1:,...]  # Omite el primer paso de tiempo\n",
        "    print(f\"x_test_new: {x_test_new.shape}\")\n",
        "\n",
        "    # Asumiendo que new_val es una única predicción que se debe añadir a cada paso de tiempo en x_test_new\n",
        "    new_val = new_val.squeeze(axis=0)  # Elimina la dimensión del batch, si es necesario\n",
        "\n",
        "    print(new_val.shape)\n",
        "    # Añadir new_val a cada elemento en x_test_new\n",
        "    x_test_new = np.concatenate((x_test_new, np.expand_dims(new_val, axis=1)), axis=1)\n",
        "\n",
        "    print(\"CX\", x_test_new.shape)\n",
        "    return x_test_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kT9Uc7sgGr1U"
      },
      "outputs": [],
      "source": [
        "#Crea cubos con su propia información de tamaño h\n",
        "def get_cubes(data, h):\n",
        "    new_data = []\n",
        "    for i in range(0, len(data)-h):\n",
        "        new_data.append(data[i:i+h])\n",
        "    new_data = np.array(new_data)\n",
        "    print(new_data.shape)\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_UVAWOyGI5j"
      },
      "source": [
        "## Codigo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyDHJvcieY6a"
      },
      "source": [
        "Variables iniciales para correr el codigo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4jB62x-HG3_k"
      },
      "outputs": [],
      "source": [
        "rows = 122\n",
        "cols = 360\n",
        "channels = 1\n",
        "window = 5\n",
        "categories = [0, 35, 70, 119, 177, 220, 255]\n",
        "horizon = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Mu2Y0IeY6a"
      },
      "source": [
        "De la carpeta con las imagenes pasarlo a un arreglo npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "liiMS6fLG7uc",
        "outputId": "67e75660-b086-4f8b-ff96-d98d84bd3a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Images shape: (1240, 122, 360)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Set the path to the folder containing the images\n",
        "path = \"./DroughtDatasetMask\"\n",
        "\n",
        "# Get a list of all the image file names in the folder\n",
        "image_files = [f for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Suponiendo que todas las imágenes tienen el tamaño deseado de 122x360\n",
        "num_images = len(image_files)  # Asegúrate de que este número corresponde al número de imágenes que deseas cargar\n",
        "\n",
        "# Verifica que tengas la cantidad correcta de archivos de imagen\n",
        "if len(image_files) != num_images:\n",
        "    raise ValueError(f\"Expected {num_images} images, but found {len(image_files)}\")\n",
        "\n",
        "# Create an empty numpy array to hold the images\n",
        "images = np.zeros((num_images, rows, cols), dtype=np.uint8)  # Asegúrate de que el tipo de datos sea correcto\n",
        "\n",
        "# Loop through the image files and add each image to the numpy array\n",
        "for i, file in enumerate(sorted(image_files)[:num_images]):  # Asegúrate de que no excedas el número de imágenes deseado\n",
        "    # Load the image using OpenCV\n",
        "    img = cv2.imread(os.path.join(path, file), cv2.IMREAD_GRAYSCALE)  # Directamente en escala de grises\n",
        "    if img.shape != (rows, cols):\n",
        "        raise ValueError(f\"The image {file} has a shape of {img.shape}, but expected {(rows, cols)}\")\n",
        "    # Add the image to the numpy array\n",
        "    images[i] = img\n",
        "\n",
        "# Save the numpy array to a file\n",
        "numpy_array_path = './DroughtDatasetMask.npy'\n",
        "np.save(numpy_array_path, images)\n",
        "\n",
        "\"Images shape: {}\".format(images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cJrgJrUeY6b"
      },
      "source": [
        "cargar dataset en formato npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5YZjO4H-LUPo",
        "outputId": "72b7aadd-62cf-4201-fc05-e7afe9dd8004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1240, 122, 360)\n"
          ]
        }
      ],
      "source": [
        "x = np.load(numpy_array_path)\n",
        "print (x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sT9hyTyxLav7",
        "outputId": "bf3df7b4-9296-4e64-d46d-9e1ca83c85cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colores [  0 255 223 190 215 172 176 212 226 224 169 194  78  69  83 168 181 222\n",
            " 200 217 177 148 165 213 210 184 218 219  76 139 204 113 198 175 156 133\n",
            " 205 225 216  90  89 162 193 211 117  82 159 154  70  99 174 187 209 214\n",
            " 110  98 126 170 220 189 173 182 178 197  72  71 221 104 206 208 138 203\n",
            " 143 188 161 119 127 150 192 166  68  81  62  52  38  36  48  67  66  34\n",
            "  59  64  57  50  40 180  77 101 201 167 130  60 129 191 195 179  41 202\n",
            " 199  94 111]\n",
            "(1240, 122, 360)\n"
          ]
        }
      ],
      "source": [
        "x = np.array([gray_quantized(i, np.array(categories)) for i in x])\n",
        "colors_greys = get_colors(x[1168])\n",
        "print(f\"Colores {colors_greys}\")\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AudRJNR_LdPY"
      },
      "outputs": [],
      "source": [
        "x_greys = np.array([recolor_greys_image(img, categories) for img in x])\n",
        "x = x_greys.astype('float32') / 255\n",
        "print(get_colors(x[1168]))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcV6EJmELe-R"
      },
      "outputs": [],
      "source": [
        "#Mostrar imágenes\n",
        "fig, axes = plt.subplots(2, 3, figsize= (10,8))\n",
        "\n",
        "data_choise = np.random.choice(range(len(x)), size= 1)[0]\n",
        "for idx, ax in enumerate(axes.flat):\n",
        "    ax.imshow(np.squeeze(x[data_choise+idx]), cmap='gray')\n",
        "    ax.set_title(f\"Frame {idx + 1}\")\n",
        "    ax.axis(\"off\")\n",
        "print(\"Displaying frames for example {}\".format(data_choise))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIsnr2RJL01q"
      },
      "outputs": [],
      "source": [
        "x_2 = agroup_window(x, window)\n",
        "print(x_2.shape)\n",
        "x_train = x_2[:int(len(x_2)*.7)]\n",
        "x_test = x_2[int(len(x_2)*.7):]\n",
        "x_validation = x_train[int(len(x_train)*.8):]\n",
        "x_train = x_train[:int(len(x_train)*.8)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqZo0aHeL34i"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(len(x_train), window, rows, cols, channels)\n",
        "x_validation = x_validation.reshape(len(x_validation), window, rows, cols, channels)\n",
        "x_test = x_test.reshape(len(x_test), window, rows, cols, channels)\n",
        "\n",
        "print(\"Forma de datos de entrenamiento: {}\".format(x_train.shape))\n",
        "print(\"Forma de datos de validación: {}\".format(x_validation.shape))\n",
        "print(\"Forma de datos de pruebas: {}\".format(x_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg2DGMBuL563"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = create_shifted_frames_2(x_train)\n",
        "x_validation, y_validation = create_shifted_frames_2(x_validation)\n",
        "x_test, y_test = create_shifted_frames_2(x_test)\n",
        "\n",
        "print(\"Training dataset shapes: {}, {}\".format(x_train.shape, y_train.shape))\n",
        "print(\"Validation dataset shapes: {}, {}\".format(x_validation.shape, y_validation.shape))\n",
        "print(\"Test dataset shapes: {}, {}\".format(x_test.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gxa8P7JwL-zR"
      },
      "outputs": [],
      "source": [
        "np.save(\"/content/x_test_mask.npy\", x_test)\n",
        "np.save(\"/content/y_test_mask.npy\", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OlOYkOv7l-r"
      },
      "outputs": [],
      "source": [
        "#Construction of Convolutional LSTM network\n",
        "inp = keras.layers.Input(shape=(None, *x_train.shape[2:]))\n",
        "#It will be constructed a 3 ConvLSTM2D layers with batch normalization,\n",
        "#Followed by a Conv3D layer for the spatiotemporal outputs.\n",
        "m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(inp)\n",
        "m = keras.layers.BatchNormalization()(m)\n",
        "m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(m)\n",
        "m = keras.layers.BatchNormalization()(m)\n",
        "m = keras.layers.ConvLSTM2D(16, (3,3), padding= \"same\", activation= \"relu\")(m)\n",
        "m = keras.layers.Conv2D(channels, (3,3), activation= \"sigmoid\", padding= \"same\")(m)\n",
        "model = keras.models.Model(inp, m)\n",
        "model.compile(loss= \"binary_crossentropy\", optimizer= \"Adam\")\n",
        "print(model.summary())\n",
        "#Callbacks\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor= \"val_loss\", patience= 6, restore_best_weights= True)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor= \"val_loss\", patience= 4)\n",
        "#Define moifiable training hyperparameters\n",
        "epochs = 20\n",
        "batch_size = 2\n",
        "#Model training\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size= batch_size,\n",
        "    epochs= epochs,\n",
        "    validation_data= (x_validation, y_validation),\n",
        "    callbacks= [early_stopping, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sffupP98hY0T"
      },
      "outputs": [],
      "source": [
        "#Guardar el modelo\n",
        "model.save(\"/content/ConvLSTM2D_Mask122_360.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtlrYgBLlvwJ"
      },
      "outputs": [],
      "source": [
        "imagenInicial = np.random.choice(range(len(x_test)), size= 1)[0]\n",
        "print(imagenInicial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsWHEqe0pAE0"
      },
      "outputs": [],
      "source": [
        "example = x_test[imagenInicial]\n",
        "\n",
        "print(example.shape)\n",
        "\n",
        "err = model.evaluate(x_test, y_test, batch_size= 2)\n",
        "print(\"El error del modelo es: {}\".format(err))\n",
        "preds = model.predict(x_test, batch_size= 2)\n",
        "print(preds.shape)\n",
        "x_test_new = add_last(x_test, preds[:])\n",
        "preds2 = model.predict(x_test_new, batch_size= 2)\n",
        "#print(preds2.shape)\n",
        "x_test_new = add_last(x_test_new, preds2[:])\n",
        "preds3 = model.predict(x_test_new, batch_size= 2)\n",
        "x_test_new = add_last(x_test_new, preds3[:])\n",
        "preds4 = model.predict(x_test_new, batch_size= 2)\n",
        "res_forecast = add_last(x_test_new, preds4[:])\n",
        "print(\"PREDSS\",res_forecast.shape)\n",
        "\n",
        "np.save(\"/content/PredictionsConvolutionLSTM_forecast_122_360_w5.npy\", res_forecast)  #Guardar el vector de predicciones\n",
        "\n",
        "modelos = []\n",
        "#agregar pred a modelos\n",
        "modelos.append(preds)\n",
        "modelos.append(preds2)\n",
        "modelos.append(preds3)\n",
        "modelos.append(preds4)\n",
        "\n",
        "\n",
        "print(\"Preds\" , preds.shape)\n",
        "print(\"Preds2\" , preds2.shape)\n",
        "print(\"Preds3\" , preds3.shape)\n",
        "print(\"Preds4\" , preds4.shape)\n",
        "print(\"Res_forecast\" , res_forecast.shape)\n",
        "print(\"x_test\" , x_test.shape)\n",
        "print(\"x_test_new\" , x_test_new.shape)\n",
        "print(\"y_test\" , y_test.shape)\n",
        "\n",
        "# Selecciona la primera imagen y elimina la dimensión de canal singular con squeeze()\n",
        "plt.imshow(preds[0].squeeze(), cmap='gray')\n",
        "plt.title(\"First Predicted Image\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ_34yImDNi9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_Positions(data, rows= 122, cols=360):\n",
        "    elements = []\n",
        "    for i in data:\n",
        "        ix = int(i/cols)\n",
        "        iy = int(np.round(((i/cols)-ix)*cols))\n",
        "        elements.append((ix,iy))\n",
        "    #print(index/cols)\n",
        "    #print((index/cols)-ix)\n",
        "    #print(((index/cols)-ix)*cols)\n",
        "    print(\"Posiciones!!! {} , {}\".format(ix, iy))\n",
        "    return elements\n",
        "\n",
        "\n",
        "#Crea cubos con su propia información de tamaño h\n",
        "def get_cubes(data, h):\n",
        "    new_data = []\n",
        "    for i in range(0, len(data)-h):\n",
        "        new_data.append(data[i:i+h])\n",
        "    new_data = np.array(new_data)\n",
        "    print(new_data.shape)\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUH5Php6DEdL"
      },
      "outputs": [],
      "source": [
        "\n",
        "classes = np.array([0, 255, 220, 177, 119, 70, 35]) # 255, 220, 177, 119, 70, 35  0\n",
        "classes_rgb = np.array([[0,0,0], [35,35,35], [70,70,70], [119,119,119], [177,177,177], [220,220,220], [255,255,255]])\n",
        "rows = 122\n",
        "cols = 360\n",
        "h = 4\n",
        "\n",
        "data = np.load(\"/content/PredictionsConvolutionLSTM_forecast_122_360_w5.npy\")\n",
        "x_test = np.load(\"/content/x_test_mask.npy\")\n",
        "y_test = np.load(\"/content/y_test_mask.npy\")\n",
        "\n",
        "print(data.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "y_test = get_cubes(y_test, h)\n",
        "\n",
        "colors = get_colors(x_test[-10,0])\n",
        "print(\"COLORSS\", colors)\n",
        "print(\"COLORS\", colors.shape)\n",
        "\n",
        "colorss = get_colors(data[-10,0])\n",
        "print(\"COLORSS\", colorss)\n",
        "\n",
        "naive = x_test[:-4]\n",
        "data = data[1:-3]\n",
        "\n",
        "#y_real = y_test[:, -h:]*255\n",
        "new_data = data[:, -h:]\n",
        "n_real = naive[:, -h:]*255\n",
        "\n",
        "#y_test = y_test[:, -h:]\n",
        "naive = naive[:, -h:]\n",
        "\n",
        "print(\"XX\")\n",
        "print(y_test.shape)\n",
        "print(new_data.shape)\n",
        "print(n_real.shape)\n",
        "\n",
        "print(min(new_data[0,0,60]))\n",
        "print(max(new_data[0,0,60]))\n",
        "\n",
        "new_data = new_data * 255\n",
        "new_data = new_data.astype(np.uint8)\n",
        "\n",
        "print(\"HEY\", new_data.shape)\n",
        "print(colorss.shape)\n",
        "print(min(new_data[0,0,60]))\n",
        "print(max(new_data[0,0,60]))\n",
        "\n",
        "new_data = new_data.reshape(new_data.shape[:-1])\n",
        "print(\"HoY\", new_data.shape)\n",
        "\n",
        "aux = []\n",
        "for i in new_data:\n",
        "    aux2 = []\n",
        "    for j in i:\n",
        "        #res = cv2.cvtColor(j, cv2.COLOR_GRAY2RGB)\n",
        "        #res = recolor_greys_image(j, classes)\n",
        "        #rgb_quantized(res, classes_rgb)\n",
        "        #res = cv2.cvtColor(res, cv2.COLOR_RGB2GRAY)\n",
        "        res = gray_quantized(j, classes)\n",
        "        res = recolor_greys_image(res, classes)\n",
        "        aux2.append(res)\n",
        "    aux.append(np.array(aux2))\n",
        "new_data = np.array(aux)\n",
        "print(\"SHAPEE\", new_data.shape)\n",
        "color_data = get_colors(new_data[-10,0])\n",
        "print(\"DCOLORS\", color_data)\n",
        "new_data = new_data.reshape(new_data.shape[0],new_data.shape[1],new_data.shape[2],new_data.shape[3],1)\n",
        "\n",
        "#y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2]))*255\n",
        "#naive = naive.reshape((naive.shape[0], naive.shape[1], naive.shape[2])) * 255\n",
        "\n",
        "plt.imshow(y_test[0,0], cmap=\"gray\")\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "plt.imshow(new_data[0,0], cmap=\"gray\")\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "plt.imshow(naive[0,0], cmap=\"gray\")\n",
        "#plt.show()\n",
        "\n",
        "y_test = y_test * 255\n",
        "naive = naive * 255\n",
        "\n",
        "print(\"YCOLORS\", get_colors(y_test[-10,0]))\n",
        "print(\"NCOLORS\", get_colors(naive[-10,0]))\n",
        "\n",
        "print(\"XS\")\n",
        "print(new_data.shape)\n",
        "print(y_test.shape)\n",
        "print(naive.shape)\n",
        "\n",
        "l_clas = len(classes)\n",
        "\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "r = 3\n",
        "c = 4\n",
        "ac = 1\n",
        "pos = 100\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(y_test[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Original_t+{}'.format(i+1))\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(new_data[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Pronóstico_t+{}'.format(i+1))\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(naive[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Naive_t+{}'.format(i+1))\n",
        "\n",
        "#plt.show()\n",
        "\n",
        "cm_f = np.zeros((l_clas, l_clas), dtype=np.uint64)\n",
        "cm_n = np.zeros((l_clas, l_clas), dtype=np.uint64)\n",
        "print(cm_f)\n",
        "\n",
        "for e in range(y_test.shape[0]):\n",
        "    for k in range(h):\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                pos1 = np.where(classes == y_test[e, k, i, j])[0][0]\n",
        "                pos2 = np.where(classes == new_data[e, k, i, j])[0][0]\n",
        "                pos3 = np.where(classes == naive[e, k, i, j])[0][0]\n",
        "                cm_f[pos1, pos2] += 1\n",
        "                cm_n[pos1, pos3] += 1\n",
        "\n",
        "print(\"Matriz de confusión de pronóstico\")\n",
        "print(cm_f)\n",
        "print(\"Matriz de confusión de naive\")\n",
        "print(cm_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX6TssIBuxzU"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,20))\n",
        "r = 3\n",
        "c = 4\n",
        "ac = 1\n",
        "pos = 100\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(y_test[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Original_t+{}'.format(i+1))\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(new_data[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Pronóstico_t+{}'.format(i+1))\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(naive[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Naive_t+{}'.format(i+1))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PlAdLYpCipv"
      },
      "source": [
        "## not working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXlls_V5CiRT"
      },
      "outputs": [],
      "source": [
        "n_images = 5  # Define cuántas imágenes quieres mostrar\n",
        "fig, axes = plt.subplots(1, n_images, figsize=(20, 4))\n",
        "for i in range(n_images):\n",
        "    for j in range(len(modelos)):\n",
        "        # Asegúrate de que cada imagen es una matriz 2D al usar squeeze()\n",
        "        axes[i].imshow(modelos[j][i].squeeze(), cmap='gray')\n",
        "        axes[i].set_title(f\"Predicted Image {i+1}\")\n",
        "        axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZi4x6tK0Tsq"
      },
      "outputs": [],
      "source": [
        "n_images = 5  # Define cuántas imágenes quieres mostrar\n",
        "fig, axes = plt.subplots(1, n_images, figsize=(20, 4))\n",
        "for i in range(n_images):\n",
        "    #Asegúrate de que cada imagen es una matriz 2D al usar squeeze()\n",
        "    print(f\"Shape of predicted: {preds[i].shape}\")\n",
        "    axes[i].imshow(preds[i].squeeze(), cmap='gray')\n",
        "    print(f\"Shape of predicted image: {preds[i].shape}\")\n",
        "    axes[i].set_title(f\"Predicted Image {i+1}\")\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZNoKSYh9sEb"
      },
      "outputs": [],
      "source": [
        "imagenInicial = np.random.choice(range(len(x_test)), size= 1)[0]\n",
        "print(imagenInicial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-FTBqqCzPcO"
      },
      "outputs": [],
      "source": [
        "\n",
        "example = x_test[imagenInicial]\n",
        "#frames = example[:4, ...]\n",
        "#original_frames = example[4:, ...]\n",
        "print(example.shape)\n",
        "#print(frames.shape)\n",
        "#print(original_frames.shape)\n",
        "for _ in range(horizon):\n",
        "    print(example.shape)\n",
        "    new_prediction = model.predict(example.reshape(1,*example.shape[0:]))\n",
        "    example = np.concatenate((example[1:], new_prediction), axis=0)\n",
        "    print(f\"example {example.shape}\")\n",
        "predictions = example[:-3]\n",
        "print(predictions.shape)\n",
        "# Selecciona la primera imagen y elimina la dimensión de canal singular con squeeze()\n",
        "plt.imshow(predictions[0].squeeze(), cmap='gray')\n",
        "plt.title(\"First Predicted Image\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpw7PAJR-FhC"
      },
      "outputs": [],
      "source": [
        "\n",
        "example = x_test[imagenInicial]\n",
        "#frames = example[:4, ...]\n",
        "#original_frames = example[4:, ...]\n",
        "print(example.shape)\n",
        "#print(frames.shape)\n",
        "#print(original_frames.shape)\n",
        "for _ in range(horizon):\n",
        "    print(example.shape)\n",
        "    new_prediction = model.predict(example.reshape(1,*example.shape[0:]))\n",
        "    example = np.concatenate((example[1:], new_prediction), axis=0)\n",
        "    print(f\"example {example.shape}\")\n",
        "predictions = example[:-3]\n",
        "print(predictions.shape)\n",
        "# Selecciona la primera imagen y elimina la dimensión de canal singular con squeeze()\n",
        "\n",
        "for i in range(horizon):\n",
        "    plt.imshow(example[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"{i+1} Predicted Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGvvfn9P_Vh0"
      },
      "outputs": [],
      "source": [
        "x_test = x_test[imagenInicial]\n",
        "for i in range(horizon):\n",
        "    plt.imshow(x_test[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"{i+1} Predicted Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YNr4xFjnGHRJ",
        "-PlAdLYpCipv"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}