{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yahred/evolutionary-computation/blob/main/EvolucionAlgorimoConvLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBAOAz4QeY6T"
      },
      "outputs": [],
      "source": [
        "%pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj2mN70-ao4t"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZAa8q8JFPbc"
      },
      "source": [
        "* Número de filtros en las capas ConvLSTM2D:\n",
        "\n",
        "Para la primera y segunda capa: 16 (puede ser cualquier entero positivo).\n",
        "Para la tercera capa: también 16 (puede ser cualquier entero positivo).\n",
        "\n",
        "* Tamaño del kernel en las capas ConvLSTM2D:\n",
        "\n",
        "Para la primera y segunda capa: (5,5) (puede ser cualquier par de enteros positivos).\n",
        "Para la tercera capa: (3,3) (puede ser cualquier par de enteros positivos).\n",
        "* Activación en las capas ConvLSTM2D y Conv2D:\n",
        "\n",
        "relu para las capas ConvLSTM2D.\n",
        "sigmoid para la capa Conv2D.\n",
        "Podrían ser 'tanh', 'softmax', etc.\n",
        "* Número de canales (channels) en la capa Conv2D:\n",
        "\n",
        "Depende de tu tarea específica (por ejemplo, 1 para la segmentación binaria, 3 para imágenes RGB).\n",
        "* Función de pérdida al compilar el modelo:\n",
        "\n",
        "binary_crossentropy en este ejemplo.\n",
        "Podrías elegir 'categorical_crossentropy', 'mean_squared_error', etc.\n",
        "* Optimizador al compilar el modelo:\n",
        "\n",
        "Adam en este ejemplo.\n",
        "Podrías elegir 'SGD', 'RMSprop', etc., y también sus hiperparámetros asociados.\n",
        "* patience para EarlyStopping:\n",
        "\n",
        "6 en este ejemplo.\n",
        "Puede ser cualquier entero positivo.\n",
        "* restore_best_weights para EarlyStopping:\n",
        "\n",
        "True en este ejemplo.\n",
        "Puede ser True o False.\n",
        "* patience para ReduceLROnPlateau:\n",
        "\n",
        "4 en este ejemplo.\n",
        "Puede ser cualquier entero positivo.\n",
        "* Epochs:\n",
        "\n",
        "20 en este ejemplo.\n",
        "Puede ser cualquier entero positivo.\n",
        "* Batch size:\n",
        "\n",
        "1 en este ejemplo.\n",
        "Puede ser cualquier entero positivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fuwvf9ZQbBqN"
      },
      "source": [
        "## Librerias y cargar dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hq2EqjYM2kcz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Input, Conv2D\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "from urllib.request import urlopen\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se descarga el dataset por medio de una petición HTTP y se extrae\n"
      ],
      "metadata": {
        "id": "FJncZlbIx_kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/Yahred/evolutionary-computation/raw/main/data/DroughtDatasetMask.zip'\n",
        "response = requests.get(url)\n",
        "data = None\n",
        "\n",
        "if response.status_code != 200:\n",
        "  display(HTML((response.text)))\n",
        "else:\n",
        "  zip_file = io.BytesIO(response.content)\n",
        "  data = zipfile.ZipFile(zip_file, 'r')\n",
        "  data.extractall()"
      ],
      "metadata": {
        "id": "YRX-mfgJugHt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNr4xFjnGHRJ"
      },
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4EBDpQpZGTpv"
      },
      "outputs": [],
      "source": [
        "def create_shifted_frames_2(data):\n",
        "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
        "    y = data[:, data.shape[1]-1, :, :]\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s3_pJVteGUFU"
      },
      "outputs": [],
      "source": [
        "#Toma todos los colores existentes en la imagen\n",
        "def get_colors(image):\n",
        "  aux = []\n",
        "  band = True\n",
        "  for i in image:\n",
        "    for j in i:\n",
        "\n",
        "      for k in aux:\n",
        "        if j.tolist() == k:\n",
        "          band = False\n",
        "          break\n",
        "      if band:\n",
        "        aux.append(j.tolist())\n",
        "      band = True\n",
        "  return np.array(aux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j1G3jCDrGWN7"
      },
      "outputs": [],
      "source": [
        "def balance_img_categories(img, palette, balancer):\n",
        "  #palette = np.sort(palette)\n",
        "  rows = len(img)\n",
        "  cols = len(img[0])\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      pos = np.where(palette == img[i,j])[0][0]\n",
        "      img[i,j] = balancer[pos]\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MIROb6RBGZML"
      },
      "outputs": [],
      "source": [
        "#Función para dada una paleta solo tomar los colores de esa paleta en la imagen\n",
        "def quantizetopalette(silf, palette, dither=False, mode=\"P\"):\n",
        "  \"\"\"Convert an RGB or L mode image to use a given P image's palette.\"\"\"\n",
        "  silf.load()\n",
        "  palette.load()\n",
        "  im = silf.im.convert(mode, 0, palette.im)\n",
        "  # the 0 above means turn OFF dithering making solid colors\n",
        "  return silf._new(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hcM1PYj9Ga99"
      },
      "outputs": [],
      "source": [
        "#Realiza las operaciones necesarias para obtener una imagen RGB por una paleta de colores\n",
        "def rgb_quantized(img, palette):\n",
        "  rows, cols = len(img), len(img[0])\n",
        "  total_vals = 1\n",
        "  for i in palette.shape:\n",
        "    total_vals *= i\n",
        "  palettedata = palette.reshape(total_vals).tolist()\n",
        "  palImage = Image.new('P', (rows, cols))\n",
        "  palImage.putpalette(palettedata*32)\n",
        "  oldImage = Image.fromarray(img).convert(\"RGB\")\n",
        "  newImage = quantizetopalette(oldImage,palImage)\n",
        "  res_image = np.asarray(newImage.convert(\"RGB\"))\n",
        "  return res_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a3jqk96wGcX1"
      },
      "outputs": [],
      "source": [
        "def gray_quantized(img, palette):\n",
        "  rows, cols = len(img), len(img[0])\n",
        "  total_vals = 1\n",
        "  for i in palette.shape:\n",
        "    total_vals *= i\n",
        "  palettedata = palette.reshape(total_vals).tolist()\n",
        "  palImage = Image.new('L', (rows, cols))\n",
        "  palImage.putpalette(palettedata*32)\n",
        "  oldImage = Image.fromarray(img, 'L')\n",
        "  newImage = quantizetopalette(oldImage,palImage, mode=\"L\")\n",
        "  res_image = np.asarray(newImage)\n",
        "  return res_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p1y6vWRJGdlb"
      },
      "outputs": [],
      "source": [
        "def recolor_greys_image(data, palette):\n",
        "    rows, cols = len(data), len(data[0])\n",
        "    aux = np.zeros((rows, cols), dtype=np.uint64)\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            aux[i,j] = min(palette, key= lambda x:abs(x-data[i,j]))\n",
        "    return aux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ec1Q5aXoGetT"
      },
      "outputs": [],
      "source": [
        "def agroup_window(data, window):\n",
        "    new_data = [data[i:window+i] for i in range(len(data)-window+1)]\n",
        "    return np.array(new_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "J21867-jGgAL"
      },
      "outputs": [],
      "source": [
        "def add_last(data, new_vals):\n",
        "    print(f\"data: {data.shape} y new_val: {new_vals.shape}\")\n",
        "    x_test_new = data[:,1:]\n",
        "    print(f\"x_test_new: {x_test_new.shape}\")\n",
        "\n",
        "    l = []\n",
        "    for i in range(len(x_test_new)):\n",
        "        l.append(np.append(x_test_new[i], new_vals[i]))\n",
        "    x_test_new = np.array(l).reshape(data.shape[:])\n",
        "    print(\"CX\", x_test_new.shape)\n",
        "    return x_test_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1ZaQ_edXGhMr"
      },
      "outputs": [],
      "source": [
        "def add_lastNew(data, new_val):\n",
        "    print(f\"data: {data.shape} y new_val: {new_val.shape}\")\n",
        "    x_test_new = data[:,1:,...]  # Omite el primer paso de tiempo\n",
        "    print(f\"x_test_new: {x_test_new.shape}\")\n",
        "\n",
        "    # Asumiendo que new_val es una única predicción que se debe añadir a cada paso de tiempo en x_test_new\n",
        "    new_val = new_val.squeeze(axis=0)  # Elimina la dimensión del batch, si es necesario\n",
        "\n",
        "    print(new_val.shape)\n",
        "    # Añadir new_val a cada elemento en x_test_new\n",
        "    x_test_new = np.concatenate((x_test_new, np.expand_dims(new_val, axis=1)), axis=1)\n",
        "\n",
        "    print(\"CX\", x_test_new.shape)\n",
        "    return x_test_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kT9Uc7sgGr1U"
      },
      "outputs": [],
      "source": [
        "#Crea cubos con su propia información de tamaño h\n",
        "def get_cubes(data, h):\n",
        "    new_data = []\n",
        "    for i in range(0, len(data)-h):\n",
        "        new_data.append(data[i:i+h])\n",
        "    new_data = np.array(new_data)\n",
        "    print(new_data.shape)\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_UVAWOyGI5j"
      },
      "source": [
        "## Codigo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyDHJvcieY6a"
      },
      "source": [
        "Variables iniciales para correr el codigo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4jB62x-HG3_k"
      },
      "outputs": [],
      "source": [
        "rows = 122\n",
        "cols = 360\n",
        "channels = 1\n",
        "window = 5\n",
        "categories = [0, 35, 70, 119, 177, 220, 255]\n",
        "horizon = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Mu2Y0IeY6a"
      },
      "source": [
        "De la carpeta con las imagenes pasarlo a un arreglo npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "liiMS6fLG7uc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f9b3650-533e-4705-b80e-05a470638842"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Images shape: (1240, 122, 360)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Set the path to the folder containing the images\n",
        "path = \"./DroughtDatasetMask\"\n",
        "\n",
        "# Get a list of all the image file names in the folder\n",
        "image_files = [f for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Suponiendo que todas las imágenes tienen el tamaño deseado de 122x360\n",
        "num_images = len(image_files)  # Asegúrate de que este número corresponde al número de imágenes que deseas cargar\n",
        "\n",
        "# Verifica que tengas la cantidad correcta de archivos de imagen\n",
        "if len(image_files) != num_images:\n",
        "    raise ValueError(f\"Expected {num_images} images, but found {len(image_files)}\")\n",
        "\n",
        "# Create an empty numpy array to hold the images\n",
        "images = np.zeros((num_images, rows, cols), dtype=np.uint8)  # Asegúrate de que el tipo de datos sea correcto\n",
        "\n",
        "# Loop through the image files and add each image to the numpy array\n",
        "for i, file in enumerate(sorted(image_files)[:num_images]):  # Asegúrate de que no excedas el número de imágenes deseado\n",
        "    # Load the image using OpenCV\n",
        "    img = cv2.imread(os.path.join(path, file), cv2.IMREAD_GRAYSCALE)  # Directamente en escala de grises\n",
        "    if img.shape != (rows, cols):\n",
        "        raise ValueError(f\"The image {file} has a shape of {img.shape}, but expected {(rows, cols)}\")\n",
        "    # Add the image to the numpy array\n",
        "    images[i] = img\n",
        "\n",
        "# Save the numpy array to a file\n",
        "numpy_array_path = './DroughtDatasetMask.npy'\n",
        "np.save(numpy_array_path, images)\n",
        "\n",
        "\"Images shape: {}\".format(images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cJrgJrUeY6b"
      },
      "source": [
        "cargar dataset en formato npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5YZjO4H-LUPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56093454-afff-42d3-c042-22755c6af08d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1240, 122, 360)\n"
          ]
        }
      ],
      "source": [
        "x = np.load(numpy_array_path)\n",
        "print (x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sT9hyTyxLav7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7403f429-f974-4de1-9b9d-5a546c39d9b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colores [  0 255 223 190 215 172 176 212 226 224 169 194  78  69  83 168 181 222\n",
            " 200 217 177 148 165 213 210 184 218 219  76 139 204 113 198 175 156 133\n",
            " 205 225 216  90  89 162 193 211 117  82 159 154  70  99 174 187 209 214\n",
            " 110  98 126 170 220 189 173 182 178 197  72  71 221 104 206 208 138 203\n",
            " 143 188 161 119 127 150 192 166  68  81  62  52  38  36  48  67  66  34\n",
            "  59  64  57  50  40 180  77 101 201 167 130  60 129 191 195 179  41 202\n",
            " 199  94 111]\n",
            "(1240, 122, 360)\n"
          ]
        }
      ],
      "source": [
        "x = np.array([gray_quantized(i, np.array(categories)) for i in x])\n",
        "colors_greys = get_colors(x[1168])\n",
        "print(f\"Colores {colors_greys}\")\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AudRJNR_LdPY"
      },
      "outputs": [],
      "source": [
        "# x_greys = np.array([recolor_greys_image(img, categories) for img in x])\n",
        "# x = x_greys.astype('float32') / 255\n",
        "# print(get_colors(x[1168]))\n",
        "# print(x.shape)\n",
        "\n",
        "\n",
        "url = 'https://github.com/Yahred/evolutionary-computation/raw/main/data/x_greys.zip'\n",
        "response = requests.get(url)\n",
        "data = None\n",
        "\n",
        "if response.status_code != 200:\n",
        "  display(HTML((response.text)))\n",
        "else:\n",
        "  zip_file = io.BytesIO(response.content)\n",
        "  data = zipfile.ZipFile(zip_file, 'r')\n",
        "  data.extractall()\n",
        "\n",
        "x_greys = np.load('./x_greys.npy')\n",
        "x = x_greys.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FcV6EJmELe-R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "72b088b7-08e0-402c-a122-98ed36987091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying frames for example 614\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Mostrar imágenes\n",
        "fig, axes = plt.subplots(2, 3, figsize= (10,8))\n",
        "\n",
        "data_choise = np.random.choice(range(len(x)), size= 1)[0]\n",
        "for idx, ax in enumerate(axes.flat):\n",
        "    ax.imshow(np.squeeze(x[data_choise+idx]), cmap='gray')\n",
        "    ax.set_title(f\"Frame {idx + 1}\")\n",
        "    ax.axis(\"off\")\n",
        "print(\"Displaying frames for example {}\".format(data_choise))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IIsnr2RJL01q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce6138f-dd51-4161-8c3c-cc82a6dc29d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1236, 5, 122, 360)\n"
          ]
        }
      ],
      "source": [
        "x_2 = agroup_window(x, window)\n",
        "print(x_2.shape)\n",
        "x_train = x_2[:int(len(x_2)*.7)]\n",
        "x_test = x_2[int(len(x_2)*.7):]\n",
        "x_validation = x_train[int(len(x_train)*.8):]\n",
        "x_train = x_train[:int(len(x_train)*.8)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nqZo0aHeL34i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ac54c6-16af-40a6-b9c8-7795ddeb83b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de datos de entrenamiento: (692, 5, 122, 360, 1)\n",
            "Forma de datos de validación: (173, 5, 122, 360, 1)\n",
            "Forma de datos de pruebas: (371, 5, 122, 360, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train = x_train.reshape(len(x_train), window, rows, cols, channels)\n",
        "x_validation = x_validation.reshape(len(x_validation), window, rows, cols, channels)\n",
        "x_test = x_test.reshape(len(x_test), window, rows, cols, channels)\n",
        "\n",
        "print(\"Forma de datos de entrenamiento: {}\".format(x_train.shape))\n",
        "print(\"Forma de datos de validación: {}\".format(x_validation.shape))\n",
        "print(\"Forma de datos de pruebas: {}\".format(x_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pg2DGMBuL563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c198282a-cfb7-438b-b913-362e98c9bad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset shapes: (692, 4, 122, 360, 1), (692, 122, 360, 1)\n",
            "Validation dataset shapes: (173, 4, 122, 360, 1), (173, 122, 360, 1)\n",
            "Test dataset shapes: (371, 4, 122, 360, 1), (371, 122, 360, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = create_shifted_frames_2(x_train)\n",
        "x_validation, y_validation = create_shifted_frames_2(x_validation)\n",
        "x_test, y_test = create_shifted_frames_2(x_test)\n",
        "\n",
        "print(\"Training dataset shapes: {}, {}\".format(x_train.shape, y_train.shape))\n",
        "print(\"Validation dataset shapes: {}, {}\".format(x_validation.shape, y_validation.shape))\n",
        "print(\"Test dataset shapes: {}, {}\".format(x_test.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Gxa8P7JwL-zR"
      },
      "outputs": [],
      "source": [
        "np.save(\"/content/x_test_mask.npy\", x_test)\n",
        "np.save(\"/content/y_test_mask.npy\", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OlOYkOv7l-r"
      },
      "outputs": [],
      "source": [
        "# #Construction of Convolutional LSTM network\n",
        "# inp = keras.layers.Input(shape=(None, *x_train.shape[2:]))\n",
        "# #It will be constructed a 3 ConvLSTM2D layers with batch normalization,\n",
        "# #Followed by a Conv3D layer for the spatiotemporal outputs.\n",
        "# m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(inp)\n",
        "# m = keras.layers.BatchNormalization()(m)\n",
        "# m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(m)\n",
        "# m = keras.layers.BatchNormalization()(m)\n",
        "# m = keras.layers.ConvLSTM2D(16, (3,3), padding= \"same\", activation= \"relu\")(m)\n",
        "# m = keras.layers.Conv2D(channels, (3,3), activation= \"sigmoid\", padding= \"same\")(m)\n",
        "# model = keras.models.Model(inp, m)\n",
        "# model.compile(loss= \"binary_crossentropy\", optimizer= \"Adam\")\n",
        "# print(model.summary())\n",
        "# #Callbacks\n",
        "# early_stopping = keras.callbacks.EarlyStopping(monitor= \"val_loss\", patience= 6, restore_best_weights= True)\n",
        "# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor= \"val_loss\", patience= 4)\n",
        "# #Define moifiable training hyperparameters\n",
        "# epochs = 20\n",
        "# batch_size = 2\n",
        "# #Model training\n",
        "# model.fit(\n",
        "#     x_train, y_train,\n",
        "#     batch_size= batch_size,\n",
        "#     epochs= epochs,\n",
        "#     validation_data= (x_validation, y_validation),\n",
        "#     callbacks= [early_stopping, reduce_lr]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sffupP98hY0T"
      },
      "outputs": [],
      "source": [
        "# #Guardar el modelo\n",
        "# model.save(\"/content/ConvLSTM2D_Mask122_360.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtlrYgBLlvwJ"
      },
      "outputs": [],
      "source": [
        "imagenInicial = np.random.choice(range(len(x_test)), size= 1)[0]\n",
        "print(imagenInicial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsWHEqe0pAE0"
      },
      "outputs": [],
      "source": [
        "example = x_test[imagenInicial]\n",
        "\n",
        "print(example.shape)\n",
        "\n",
        "err = model.evaluate(x_test, y_test, batch_size= 2)\n",
        "print(\"El error del modelo es: {}\".format(err))\n",
        "preds = model.predict(x_test, batch_size= 2)\n",
        "print(preds.shape)\n",
        "x_test_new = add_last(x_test, preds[:])\n",
        "preds2 = model.predict(x_test_new, batch_size= 2)\n",
        "#print(preds2.shape)\n",
        "x_test_new = add_last(x_test_new, preds2[:])\n",
        "preds3 = model.predict(x_test_new, batch_size= 2)\n",
        "x_test_new = add_last(x_test_new, preds3[:])\n",
        "preds4 = model.predict(x_test_new, batch_size= 2)\n",
        "res_forecast = add_last(x_test_new, preds4[:])\n",
        "print(\"PREDSS\",res_forecast.shape)\n",
        "\n",
        "np.save(\"/content/PredictionsConvolutionLSTM_forecast_122_360_w5.npy\", res_forecast)  #Guardar el vector de predicciones\n",
        "\n",
        "modelos = []\n",
        "#agregar pred a modelos\n",
        "modelos.append(preds)\n",
        "modelos.append(preds2)\n",
        "modelos.append(preds3)\n",
        "modelos.append(preds4)\n",
        "\n",
        "\n",
        "print(\"Preds\" , preds.shape)\n",
        "print(\"Preds2\" , preds2.shape)\n",
        "print(\"Preds3\" , preds3.shape)\n",
        "print(\"Preds4\" , preds4.shape)\n",
        "print(\"Res_forecast\" , res_forecast.shape)\n",
        "print(\"x_test\" , x_test.shape)\n",
        "print(\"x_test_new\" , x_test_new.shape)\n",
        "print(\"y_test\" , y_test.shape)\n",
        "\n",
        "# Selecciona la primera imagen y elimina la dimensión de canal singular con squeeze()\n",
        "plt.imshow(preds[0].squeeze(), cmap='gray')\n",
        "plt.title(\"First Predicted Image\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ_34yImDNi9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_Positions(data, rows= 122, cols=360):\n",
        "    elements = []\n",
        "    for i in data:\n",
        "        ix = int(i/cols)\n",
        "        iy = int(np.round(((i/cols)-ix)*cols))\n",
        "        elements.append((ix,iy))\n",
        "    #print(index/cols)\n",
        "    #print((index/cols)-ix)\n",
        "    #print(((index/cols)-ix)*cols)\n",
        "    print(\"Posiciones!!! {} , {}\".format(ix, iy))\n",
        "    return elements\n",
        "\n",
        "\n",
        "#Crea cubos con su propia información de tamaño h\n",
        "def get_cubes(data, h):\n",
        "    new_data = []\n",
        "    for i in range(0, len(data)-h):\n",
        "        new_data.append(data[i:i+h])\n",
        "    new_data = np.array(new_data)\n",
        "    print(new_data.shape)\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUH5Php6DEdL"
      },
      "outputs": [],
      "source": [
        "\n",
        "classes = np.array([0, 255, 220, 177, 119, 70, 35]) # 255, 220, 177, 119, 70, 35  0\n",
        "classes_rgb = np.array([[0,0,0], [35,35,35], [70,70,70], [119,119,119], [177,177,177], [220,220,220], [255,255,255]])\n",
        "rows = 122\n",
        "cols = 360\n",
        "h = 4\n",
        "\n",
        "data = np.load(\"/content/PredictionsConvolutionLSTM_forecast_122_360_w5.npy\")\n",
        "x_test = np.load(\"/content/x_test_mask.npy\")\n",
        "y_test = np.load(\"/content/y_test_mask.npy\")\n",
        "\n",
        "print(data.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "y_test = get_cubes(y_test, h)\n",
        "\n",
        "colors = get_colors(x_test[-10,0])\n",
        "print(\"COLORSS\", colors)\n",
        "print(\"COLORS\", colors.shape)\n",
        "\n",
        "colorss = get_colors(data[-10,0])\n",
        "print(\"COLORSS\", colorss)\n",
        "\n",
        "naive = x_test[:-4]\n",
        "data = data[1:-3]\n",
        "\n",
        "#y_real = y_test[:, -h:]*255\n",
        "new_data = data[:, -h:]\n",
        "n_real = naive[:, -h:]*255\n",
        "\n",
        "#y_test = y_test[:, -h:]\n",
        "naive = naive[:, -h:]\n",
        "\n",
        "print(\"XX\")\n",
        "print(y_test.shape)\n",
        "print(new_data.shape)\n",
        "print(n_real.shape)\n",
        "\n",
        "print(min(new_data[0,0,60]))\n",
        "print(max(new_data[0,0,60]))\n",
        "\n",
        "new_data = new_data * 255\n",
        "new_data = new_data.astype(np.uint8)\n",
        "\n",
        "print(\"HEY\", new_data.shape)\n",
        "print(colorss.shape)\n",
        "print(min(new_data[0,0,60]))\n",
        "print(max(new_data[0,0,60]))\n",
        "\n",
        "new_data = new_data.reshape(new_data.shape[:-1])\n",
        "print(\"HoY\", new_data.shape)\n",
        "\n",
        "aux = []\n",
        "for i in new_data:\n",
        "    aux2 = []\n",
        "    for j in i:\n",
        "        #res = cv2.cvtColor(j, cv2.COLOR_GRAY2RGB)\n",
        "        #res = recolor_greys_image(j, classes)\n",
        "        #rgb_quantized(res, classes_rgb)\n",
        "        #res = cv2.cvtColor(res, cv2.COLOR_RGB2GRAY)\n",
        "        res = gray_quantized(j, classes)\n",
        "        res = recolor_greys_image(res, classes)\n",
        "        aux2.append(res)\n",
        "    aux.append(np.array(aux2))\n",
        "new_data = np.array(aux)\n",
        "print(\"SHAPEE\", new_data.shape)\n",
        "color_data = get_colors(new_data[-10,0])\n",
        "print(\"DCOLORS\", color_data)\n",
        "new_data = new_data.reshape(new_data.shape[0],new_data.shape[1],new_data.shape[2],new_data.shape[3],1)\n",
        "\n",
        "#y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2]))*255\n",
        "#naive = naive.reshape((naive.shape[0], naive.shape[1], naive.shape[2])) * 255\n",
        "\n",
        "plt.imshow(y_test[0,0], cmap=\"gray\")\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "plt.imshow(new_data[0,0], cmap=\"gray\")\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "plt.imshow(naive[0,0], cmap=\"gray\")\n",
        "#plt.show()\n",
        "\n",
        "y_test = y_test * 255\n",
        "naive = naive * 255\n",
        "\n",
        "print(\"YCOLORS\", get_colors(y_test[-10,0]))\n",
        "print(\"NCOLORS\", get_colors(naive[-10,0]))\n",
        "\n",
        "print(\"XS\")\n",
        "print(new_data.shape)\n",
        "print(y_test.shape)\n",
        "print(naive.shape)\n",
        "\n",
        "l_clas = len(classes)\n",
        "\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "r = 3\n",
        "c = 4\n",
        "ac = 1\n",
        "pos = 100\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(y_test[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Original_t+{}'.format(i+1))\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(new_data[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Pronóstico_t+{}'.format(i+1))\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(naive[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Naive_t+{}'.format(i+1))\n",
        "\n",
        "#plt.show()\n",
        "\n",
        "cm_f = np.zeros((l_clas, l_clas), dtype=np.uint64)\n",
        "cm_n = np.zeros((l_clas, l_clas), dtype=np.uint64)\n",
        "print(cm_f)\n",
        "\n",
        "for e in range(y_test.shape[0]):\n",
        "    for k in range(h):\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                pos1 = np.where(classes == y_test[e, k, i, j])[0][0]\n",
        "                pos2 = np.where(classes == new_data[e, k, i, j])[0][0]\n",
        "                pos3 = np.where(classes == naive[e, k, i, j])[0][0]\n",
        "                cm_f[pos1, pos2] += 1\n",
        "                cm_n[pos1, pos3] += 1\n",
        "\n",
        "print(\"Matriz de confusión de pronóstico\")\n",
        "print(cm_f)\n",
        "print(\"Matriz de confusión de naive\")\n",
        "print(cm_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX6TssIBuxzU"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,20))\n",
        "r = 3\n",
        "c = 4\n",
        "ac = 1\n",
        "pos = 100\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(y_test[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Original_t+{}'.format(i+1))\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(new_data[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Pronóstico_t+{}'.format(i+1))\n",
        "for i in range(h):\n",
        "    fig.add_subplot(r, c, ac)\n",
        "    ac += 1\n",
        "    plt.imshow(naive[pos,i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Naive_t+{}'.format(i+1))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PlAdLYpCipv"
      },
      "source": [
        "## not working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXlls_V5CiRT"
      },
      "outputs": [],
      "source": [
        "n_images = 5  # Define cuántas imágenes quieres mostrar\n",
        "fig, axes = plt.subplots(1, n_images, figsize=(20, 4))\n",
        "for i in range(n_images):\n",
        "    for j in range(len(modelos)):\n",
        "        # Asegúrate de que cada imagen es una matriz 2D al usar squeeze()\n",
        "        axes[i].imshow(modelos[j][i].squeeze(), cmap='gray')\n",
        "        axes[i].set_title(f\"Predicted Image {i+1}\")\n",
        "        axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZi4x6tK0Tsq"
      },
      "outputs": [],
      "source": [
        "n_images = 5  # Define cuántas imágenes quieres mostrar\n",
        "fig, axes = plt.subplots(1, n_images, figsize=(20, 4))\n",
        "for i in range(n_images):\n",
        "    #Asegúrate de que cada imagen es una matriz 2D al usar squeeze()\n",
        "    print(f\"Shape of predicted: {preds[i].shape}\")\n",
        "    axes[i].imshow(preds[i].squeeze(), cmap='gray')\n",
        "    print(f\"Shape of predicted image: {preds[i].shape}\")\n",
        "    axes[i].set_title(f\"Predicted Image {i+1}\")\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZNoKSYh9sEb"
      },
      "outputs": [],
      "source": [
        "imagenInicial = np.random.choice(range(len(x_test)), size= 1)[0]\n",
        "print(imagenInicial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-FTBqqCzPcO"
      },
      "outputs": [],
      "source": [
        "\n",
        "example = x_test[imagenInicial]\n",
        "#frames = example[:4, ...]\n",
        "#original_frames = example[4:, ...]\n",
        "print(example.shape)\n",
        "#print(frames.shape)\n",
        "#print(original_frames.shape)\n",
        "for _ in range(horizon):\n",
        "    print(example.shape)\n",
        "    new_prediction = model.predict(example.reshape(1,*example.shape[0:]))\n",
        "    example = np.concatenate((example[1:], new_prediction), axis=0)\n",
        "    print(f\"example {example.shape}\")\n",
        "predictions = example[:-3]\n",
        "print(predictions.shape)\n",
        "# Selecciona la primera imagen y elimina la dimensión de canal singular con squeeze()\n",
        "plt.imshow(predictions[0].squeeze(), cmap='gray')\n",
        "plt.title(\"First Predicted Image\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpw7PAJR-FhC"
      },
      "outputs": [],
      "source": [
        "\n",
        "example = x_test[imagenInicial]\n",
        "#frames = example[:4, ...]\n",
        "#original_frames = example[4:, ...]\n",
        "print(example.shape)\n",
        "#print(frames.shape)\n",
        "#print(original_frames.shape)\n",
        "for _ in range(horizon):\n",
        "    print(example.shape)\n",
        "    new_prediction = model.predict(example.reshape(1,*example.shape[0:]))\n",
        "    example = np.concatenate((example[1:], new_prediction), axis=0)\n",
        "    print(f\"example {example.shape}\")\n",
        "predictions = example[:-3]\n",
        "print(predictions.shape)\n",
        "# Selecciona la primera imagen y elimina la dimensión de canal singular con squeeze()\n",
        "\n",
        "for i in range(horizon):\n",
        "    plt.imshow(example[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"{i+1} Predicted Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGvvfn9P_Vh0"
      },
      "outputs": [],
      "source": [
        "x_test = x_test[imagenInicial]\n",
        "for i in range(horizon):\n",
        "    plt.imshow(x_test[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"{i+1} Predicted Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimización mediante GAc"
      ],
      "metadata": {
        "id": "YX8vsW6k0VRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define el algoritmo genético compacto"
      ],
      "metadata": {
        "id": "zCl08lK-0sfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Individual:\n",
        "    def __init__(self, chrom: list[int]) -> None:\n",
        "        self.chrom = chrom\n",
        "        self.fitness = None\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return '{} Fitness: {}'.format(self.chrom, self.fitness)\n",
        "\n",
        "\n",
        "def initialize_probs(num_genes: int) -> list[float]:\n",
        "    return [0.5 for _ in range(num_genes)]\n",
        "\n",
        "\n",
        "def create_individual(probs: list[float]):\n",
        "    chrom = ['1' if random.uniform(0, 1) < prob else '0' for prob in probs]\n",
        "    return Individual(''.join(chrom))\n",
        "\n",
        "\n",
        "def compete(a: Individual, b: Individual, fitness: callable, fitness_min: bool):\n",
        "    a.fitness = fitness(a.chrom)\n",
        "    b.fitness = fitness(b.chrom)\n",
        "\n",
        "    if a.fitness < b.fitness and fitness_min:\n",
        "        return a, b\n",
        "\n",
        "    if a.fitness > b.fitness and not fitness_min:\n",
        "        return a, b\n",
        "\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def adjust_probs(probs: list[float], winner: Individual, loser: Individual, poblacion: int):\n",
        "    new_probs = []\n",
        "\n",
        "    for i in range(len(probs)):\n",
        "        loser_gen = loser.chrom[i]\n",
        "        winner_gen = winner.chrom[i]\n",
        "\n",
        "        if winner_gen == loser_gen:\n",
        "            new_probs.append(probs[i])\n",
        "            continue\n",
        "\n",
        "        if winner_gen == '0':\n",
        "            new_probs.append(probs[i] - (1 / poblacion))\n",
        "            continue\n",
        "\n",
        "        new_probs.append(probs[i] + (1 / poblacion))\n",
        "    return new_probs\n",
        "\n",
        "\n",
        "def has_converged(probs: list[float], convergence_criteria: float):\n",
        "    for prob in probs:\n",
        "        diff = 1 - prob\n",
        "        if diff > convergence_criteria:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def update_hof(winner: Individual, hall_of_fame: list[Individual], size: int, fitness_min: bool = False):\n",
        "  if not hall_of_fame:\n",
        "    hall_of_fame.append(winner)\n",
        "    return\n",
        "\n",
        "  if not fitness_min and hall_of_fame[-1].fitness > winner.fitness and len(hall_of_fame) == size:\n",
        "    return\n",
        "\n",
        "  if fitness_min and hall_of_fame[-1].fitness < winner.fitness and len(hall_of_fame) == size:\n",
        "    return\n",
        "\n",
        "  insertion_point = 0\n",
        "  for i in range(len(hall_of_fame) - 1, -1, -1):\n",
        "    ancestor = hall_of_fame[i]\n",
        "    if not fitness_min and ancestor.fitness > winner.fitness:\n",
        "      insertion_point = i + 1\n",
        "      break\n",
        "\n",
        "    if fitness_min and ancestor.fitness < winner.fitness:\n",
        "      insertion_point = i + 1\n",
        "      break\n",
        "\n",
        "  if insertion_point == len(hall_of_fame):\n",
        "    hall_of_fame.append(winner)\n",
        "    return\n",
        "\n",
        "  prev = None\n",
        "  for i in range(insertion_point, size):\n",
        "    if not prev:\n",
        "      prev = hall_of_fame[i]\n",
        "      hall_of_fame[i] = winner\n",
        "      continue\n",
        "\n",
        "    if len(hall_of_fame) <= i and len(hall_of_fame) < size:\n",
        "      hall_of_fame.append(prev)\n",
        "      break\n",
        "\n",
        "    aux = hall_of_fame[i]\n",
        "    hall_of_fame[i] = prev\n",
        "    prev = aux\n",
        "\n",
        "\n",
        "def evolve(fitness: callable, num_genes: int, generations: int, poblacion: int = 50, convergence_criteria=0.001, fitness_min=False, hof = 1):\n",
        "    best = None\n",
        "    probs = initialize_probs(num_genes)\n",
        "    hall_of_fame: list[Individual] = []\n",
        "\n",
        "    for _ in range(generations):\n",
        "        a = create_individual(probs)\n",
        "        b = create_individual(probs)\n",
        "\n",
        "        winner, loser = compete(a, b, fitness, fitness_min)\n",
        "\n",
        "        if not best:\n",
        "            best = winner\n",
        "        elif winner.fitness > best.fitness and not fitness_min:\n",
        "            best = winner\n",
        "        elif winner.fitness < best.fitness and fitness_min:\n",
        "            best = winner\n",
        "\n",
        "        if hof > 1:\n",
        "          update_hof(winner, hall_of_fame, hof, fitness_min)\n",
        "\n",
        "        probs = adjust_probs(probs, winner, loser, poblacion)\n",
        "\n",
        "        if has_converged(probs, convergence_criteria):\n",
        "            break\n",
        "\n",
        "    if hof > 1:\n",
        "      return best, hall_of_fame\n",
        "\n",
        "    return best.chrom, best.fitness"
      ],
      "metadata": {
        "id": "0cU_--7M0veY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se definen los hiperparámetros a evolucionar:\n",
        "   \n",
        "\n",
        "*   batch_size\n",
        "*   optimizer\n",
        "*   learning_rate\n",
        "*   loss\n",
        "\n"
      ],
      "metadata": {
        "id": "ge5IuZWP06Oc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos una clase HiperParametro que nos ayudará a decodificar a los individuos"
      ],
      "metadata": {
        "id": "svpaiFgj1n6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_BITS_DECIMAL = 4\n",
        "\n",
        "class HiperParametro:\n",
        "    def __init__(self, nombre, n_bits, posibles_opciones, es_decimal = False) -> None:\n",
        "        self.nombre = nombre\n",
        "        self.n_bits = n_bits\n",
        "        self.posibles_opciones = posibles_opciones\n",
        "        self.es_decimal = es_decimal\n",
        "\n",
        "    def transformar_decimal(self, bin: str):\n",
        "        n_bits = N_BITS_DECIMAL\n",
        "        decimal = '0.'\n",
        "\n",
        "        es_uno = True\n",
        "        for _ in range(0, len(bin), n_bits):\n",
        "            digito = int(bin[: n_bits], 2)\n",
        "            bin = bin[n_bits :]\n",
        "\n",
        "            if digito > 9 or digito == 0:\n",
        "                digito = 0\n",
        "            else:\n",
        "                es_uno = False\n",
        "\n",
        "            decimal += str(digito)\n",
        "\n",
        "        return float(decimal)\n",
        "\n",
        "    def transformar_rango(self, seleccion: int):\n",
        "        inferior, superior = self.posibles_opciones\n",
        "        if seleccion + inferior > superior:\n",
        "            return superior\n",
        "        return seleccion + inferior\n",
        "\n",
        "    def obtener_seleccion(self, bin: str):\n",
        "        seleccion = int(bin, 2)\n",
        "\n",
        "        if self.es_decimal:\n",
        "            return self.transformar_decimal(bin)\n",
        "\n",
        "        if isinstance(self.posibles_opciones, list):\n",
        "            i = seleccion if seleccion < len(self.posibles_opciones) else len(self.posibles_opciones) - 1\n",
        "            return self.posibles_opciones[i]\n",
        "\n",
        "        if isinstance(self.posibles_opciones, tuple):\n",
        "            return self.transformar_rango(seleccion)\n",
        "\n",
        "        return 0"
      ],
      "metadata": {
        "id": "AqqUhwMPP-V_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos dos listas de la clase HiperParametro para el conjunto de hiperparametros que vamos a entrenar"
      ],
      "metadata": {
        "id": "Uf27l4kBa5cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_MODULOS = 6\n",
        "hiper_parametros_modelo = [\n",
        "  HiperParametro('loss', 3, ['binary_crossentropy', 'mse', 'mae']),\n",
        "  HiperParametro('batch_size', 3, (2, 8)),\n",
        "  HiperParametro('optimizer', 2, ['adam', 'rmsprop', 'sgd']),\n",
        "  HiperParametro('n_modulos', 3, (1, MAX_MODULOS)),\n",
        "]\n",
        "\n",
        "hiper_parametros_arq = [\n",
        "  HiperParametro('kernel', 1, [(3,3), (5,5)]),\n",
        "  HiperParametro('filters', 4, (8, 32)),\n",
        "  HiperParametro('dropout', 12, N_BITS_DECIMAL, True),\n",
        "  HiperParametro('recurrent_dropout', 12, N_BITS_DECIMAL, True),\n",
        "]"
      ],
      "metadata": {
        "id": "HNR3oNWta5vW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos una función que nos ayudará a decodificar un individuo"
      ],
      "metadata": {
        "id": "_NYMr53tazF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decodificar_ind(ind: str):\n",
        "  bin = ind\n",
        "  ind_decodificado = {}\n",
        "\n",
        "  for hiper_parametro in hiper_parametros_modelo:\n",
        "    bin_seleccion = bin[0 : hiper_parametro.n_bits]\n",
        "    bin = bin[hiper_parametro.n_bits :]\n",
        "\n",
        "    ind_decodificado[hiper_parametro.nombre] = hiper_parametro.obtener_seleccion(bin_seleccion)\n",
        "\n",
        "  ind_decodificado['modulos'] = []\n",
        "  for _ in range(ind_decodificado['n_modulos']):\n",
        "    modulo = {}\n",
        "    for hiper_parametro in hiper_parametros_arq:\n",
        "      bin_seleccion = bin[0 : hiper_parametro.n_bits]\n",
        "      bin = bin[hiper_parametro.n_bits : ]\n",
        "\n",
        "      modulo[hiper_parametro.nombre] = hiper_parametro.obtener_seleccion(bin_seleccion)\n",
        "    ind_decodificado['modulos'].append(modulo)\n",
        "\n",
        "  return ind_decodificado"
      ],
      "metadata": {
        "id": "vL7J7ospaykI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos una función para crear la arquitectura de nuestro modelo proviniente de un individuo decodificado"
      ],
      "metadata": {
        "id": "OJy6TBhMbYst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_modelo(decoded_ind):\n",
        "  arquitectura = [\n",
        "      Input(shape=(None, *x_train.shape[2:])),\n",
        "  ]\n",
        "\n",
        "  for modulo in decoded_ind['modulos']:\n",
        "    filters = modulo['filters']\n",
        "    kernel = modulo['kernel']\n",
        "    dropout = modulo['dropout']\n",
        "    recurrent_dropout = modulo['recurrent_dropout']\n",
        "\n",
        "    arquitectura += [\n",
        "       ConvLSTM2D(modulo['filters'], modulo['kernel'] , padding=\"same\", dropout=dropout,  return_sequences=True, activation=\"relu\"),\n",
        "       BatchNormalization()\n",
        "    ]\n",
        "\n",
        "  arquitectura += [\n",
        "      ConvLSTM2D(16, (3,3), padding= \"same\", activation= \"relu\"),\n",
        "      Conv2D(channels, (3,3), activation=\"sigmoid\", padding=\"same\")\n",
        "    ]\n",
        "\n",
        "  model = keras.models.Sequential(arquitectura)\n",
        "  model.compile(loss=decoded_ind['loss'], optimizer=decoded_ind['optimizer'])\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "6SkIJ_GBb4Q1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos la función que realizará el entrenamiento parcial"
      ],
      "metadata": {
        "id": "MCcjUKqyubHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entrenamiento_parcial(modelo: keras.Model, decoded_ind):\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor= \"val_loss\", patience=6, restore_best_weights= True)\n",
        "  reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor= \"val_loss\", patience= 4)\n",
        "  epochs = 1\n",
        "  batch_size = decoded_ind['batch_size']\n",
        "\n",
        "  history = modelo.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size= batch_size,\n",
        "    epochs= epochs,\n",
        "    validation_data= (x_validation, y_validation),\n",
        "    callbacks= [early_stopping, reduce_lr],\n",
        "  )\n",
        "\n",
        "  validation_loss, = history.history['val_loss']\n",
        "\n",
        "  return validation_loss"
      ],
      "metadata": {
        "id": "prGlqx6luhwy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define la función de aptitud"
      ],
      "metadata": {
        "id": "EqcnDuUebVa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness(ind: str):\n",
        "  decoded_ind = decodificar_ind(ind)\n",
        "  modelo = crear_modelo(decoded_ind)\n",
        "  val_loss = entrenamiento_parcial(modelo, decoded_ind)\n",
        "  return val_loss"
      ],
      "metadata": {
        "id": "uzMQxqo71NH0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el tamaño del cromosoma del individuo"
      ],
      "metadata": {
        "id": "Je44ZyxsS-nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LONGITUD_CROMOSOMA = sum([param.n_bits for param in hiper_parametros_modelo])\n",
        "LONGITUD_CROMOSOMA += sum([param.n_bits for param in hiper_parametros_arq]) * MAX_MODULOS\n",
        "\n",
        "LONGITUD_CROMOSOMA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJJnqAnsTCOV",
        "outputId": "e01411e1-3601-4d5c-9bd5-dc12a710bc24"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "185"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realizan pruebas con un individuo"
      ],
      "metadata": {
        "id": "7XD-4QotVdcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind = ''.join([random.choice(['0', '1']) for _ in range(LONGITUD_CROMOSOMA)])\n",
        "ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QgN7LBAkVg6O",
        "outputId": "4a4e99a2-8602-447b-ff32-bbdeebcae799"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10011100001101001001100101011100110100111111000100011100010001100000001010101100000110001010111000100100100110010101101000100000001001100011101011110001010111000110011001110100100111001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = decodificar_ind(ind)\n",
        "decoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDnix98gV1gP",
        "outputId": "a5e757b0-2bba-4691-d4f3-68e8a6a2b242"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 'mae',\n",
              " 'batch_size': 8,\n",
              " 'optimizer': 'adam',\n",
              " 'n_modulos': 2,\n",
              " 'modulos': [{'kernel': (5, 5),\n",
              "   'filters': 12,\n",
              "   'dropout': 0.995,\n",
              "   'recurrent_dropout': 0.003},\n",
              "  {'kernel': (5, 5),\n",
              "   'filters': 22,\n",
              "   'dropout': 0.238,\n",
              "   'recurrent_dropout': 0.8}]}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generations = 10\n",
        "poblacion = 100\n",
        "hof = 3\n",
        "best, hof = evolve(fitness, LONGITUD_CROMOSOMA, fitness_min=True, hof=hof, generations=generations, poblacion=poblacion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic-DgxpTlJRc",
        "outputId": "35c8b0dc-e031-45d5-b17f-cb8ce3c2be3c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d (ConvLSTM2D)    (None, None, 122, 360,    24060     \n",
            "                             15)                                 \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, None, 122, 360,    60        \n",
            " Normalization)              15)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_1 (ConvLSTM2D)  (None, None, 122, 360,    40656     \n",
            "                             14)                                 \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, None, 122, 360,    56        \n",
            " chNormalization)            14)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_2 (ConvLSTM2D)  (None, None, 122, 360,    35152     \n",
            "                             13)                                 \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, None, 122, 360,    52        \n",
            " chNormalization)            13)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_3 (ConvLSTM2D)  (None, 122, 360, 16)      16768     \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116949 (456.83 KB)\n",
            "Trainable params: 116865 (456.50 KB)\n",
            "Non-trainable params: 84 (336.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "87/87 [==============================] - 133s 1s/step - loss: 0.0436 - val_loss: 0.4320 - lr: 0.0010\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_4 (ConvLSTM2D)  (None, None, 122, 360,    18304     \n",
            "                             22)                                 \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, None, 122, 360,    88        \n",
            " chNormalization)            22)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_5 (ConvLSTM2D)  (None, None, 122, 360,    40848     \n",
            "                             12)                                 \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, None, 122, 360,    48        \n",
            " chNormalization)            12)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_6 (ConvLSTM2D)  (None, None, 122, 360,    36456     \n",
            "                             14)                                 \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, None, 122, 360,    56        \n",
            " chNormalization)            14)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_7 (ConvLSTM2D)  (None, None, 122, 360,    27544     \n",
            "                             11)                                 \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, None, 122, 360,    44        \n",
            " chNormalization)            11)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_8 (ConvLSTM2D)  (None, None, 122, 360,    57076     \n",
            "                             19)                                 \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, None, 122, 360,    76        \n",
            " chNormalization)            19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_9 (ConvLSTM2D)  (None, None, 122, 360,    10480     \n",
            "                             10)                                 \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, None, 122, 360,    40        \n",
            " chNormalization)            10)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_10 (ConvLSTM2D  (None, 122, 360, 16)      15040     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 206245 (805.64 KB)\n",
            "Trainable params: 206069 (804.96 KB)\n",
            "Non-trainable params: 176 (704.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "139/139 [==============================] - 242s 2s/step - loss: 0.0530 - val_loss: 0.4247 - lr: 0.0010\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_11 (ConvLSTM2D  (None, None, 122, 360,    55292     \n",
            " )                           23)                                 \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, None, 122, 360,    92        \n",
            " chNormalization)            23)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_12 (ConvLSTM2D  (None, 122, 360, 16)      22528     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 78057 (304.91 KB)\n",
            "Trainable params: 78011 (304.73 KB)\n",
            "Non-trainable params: 46 (184.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "87/87 [==============================] - 61s 622ms/step - loss: 0.1823 - val_loss: 0.5622 - lr: 0.0010\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_13 (ConvLSTM2D  (None, None, 122, 360,    15200     \n",
            " )                           20)                                 \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, None, 122, 360,    80        \n",
            " tchNormalization)           20)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_14 (ConvLSTM2D  (None, None, 122, 360,    62968     \n",
            " )                           17)                                 \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, None, 122, 360,    68        \n",
            " tchNormalization)           17)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_15 (ConvLSTM2D  (None, None, 122, 360,    30976     \n",
            " )                           22)                                 \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, None, 122, 360,    88        \n",
            " tchNormalization)           22)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_16 (ConvLSTM2D  (None, None, 122, 360,    30320     \n",
            " )                           20)                                 \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, None, 122, 360,    80        \n",
            " tchNormalization)           20)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_17 (ConvLSTM2D  (None, 122, 360, 16)      20800     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160725 (627.83 KB)\n",
            "Trainable params: 160567 (627.21 KB)\n",
            "Non-trainable params: 158 (632.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "87/87 [==============================] - 153s 2s/step - loss: 0.0464 - val_loss: 0.4272 - lr: 0.0010\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_18 (ConvLSTM2D  (None, None, 122, 360,    27264     \n",
            " )                           16)                                 \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, None, 122, 360,    64        \n",
            " tchNormalization)           16)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_19 (ConvLSTM2D  (None, 122, 360, 16)      18496     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45969 (179.57 KB)\n",
            "Trainable params: 45937 (179.44 KB)\n",
            "Non-trainable params: 32 (128.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "87/87 [==============================] - 49s 494ms/step - loss: 0.0495 - val_loss: 0.2337 - lr: 0.0010\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_20 (ConvLSTM2D  (None, None, 122, 360,    13756     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_21 (ConvLSTM2D  (None, None, 122, 360,    30324     \n",
            " )                           21)                                 \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, None, 122, 360,    84        \n",
            " tchNormalization)           21)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_22 (ConvLSTM2D  (None, None, 122, 360,    9756      \n",
            " )                           9)                                  \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, None, 122, 360,    36        \n",
            " tchNormalization)           9)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_23 (ConvLSTM2D  (None, 122, 360, 16)      14464     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68641 (268.13 KB)\n",
            "Trainable params: 68543 (267.75 KB)\n",
            "Non-trainable params: 98 (392.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "99/99 [==============================] - 100s 851ms/step - loss: 0.0445 - val_loss: 0.4486 - lr: 0.0010\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_24 (ConvLSTM2D  (None, None, 122, 360,    38076     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_25 (ConvLSTM2D  (None, None, 122, 360,    13440     \n",
            " )                           12)                                 \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, None, 122, 360,    48        \n",
            " tchNormalization)           12)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_26 (ConvLSTM2D  (None, None, 122, 360,    25344     \n",
            " )                           11)                                 \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, None, 122, 360,    44        \n",
            " tchNormalization)           11)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_27 (ConvLSTM2D  (None, None, 122, 360,    52272     \n",
            " )                           18)                                 \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, None, 122, 360,    72        \n",
            " tchNormalization)           18)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_28 (ConvLSTM2D  (None, None, 122, 360,    25384     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_29 (ConvLSTM2D  (None, 122, 360, 16)      20224     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 175201 (684.38 KB)\n",
            "Trainable params: 175043 (683.76 KB)\n",
            "Non-trainable params: 158 (632.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "116/116 [==============================] - 191s 1s/step - loss: 0.4265 - val_loss: 0.4443 - lr: 0.0100\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_30 (ConvLSTM2D  (None, None, 122, 360,    55292     \n",
            " )                           23)                                 \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, None, 122, 360,    92        \n",
            " tchNormalization)           23)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_31 (ConvLSTM2D  (None, None, 122, 360,    86080     \n",
            " )                           20)                                 \n",
            "                                                                 \n",
            " batch_normalization_24 (Ba  (None, None, 122, 360,    80        \n",
            " tchNormalization)           20)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_32 (ConvLSTM2D  (None, 122, 360, 16)      20800     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 162489 (634.72 KB)\n",
            "Trainable params: 162403 (634.39 KB)\n",
            "Non-trainable params: 86 (344.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "99/99 [==============================] - 111s 1s/step - loss: 0.0386 - val_loss: 0.4152 - lr: 0.0010\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_33 (ConvLSTM2D  (None, None, 122, 360,    2624      \n",
            " )                           8)                                  \n",
            "                                                                 \n",
            " batch_normalization_25 (Ba  (None, None, 122, 360,    32        \n",
            " tchNormalization)           8)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_34 (ConvLSTM2D  (None, None, 122, 360,    12480     \n",
            " )                           15)                                 \n",
            "                                                                 \n",
            " batch_normalization_26 (Ba  (None, None, 122, 360,    60        \n",
            " tchNormalization)           15)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_35 (ConvLSTM2D  (None, None, 122, 360,    25040     \n",
            " )                           10)                                 \n",
            "                                                                 \n",
            " batch_normalization_27 (Ba  (None, None, 122, 360,    40        \n",
            " tchNormalization)           10)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_36 (ConvLSTM2D  (None, None, 122, 360,    10816     \n",
            " )                           13)                                 \n",
            "                                                                 \n",
            " batch_normalization_28 (Ba  (None, None, 122, 360,    52        \n",
            " tchNormalization)           13)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_37 (ConvLSTM2D  (None, 122, 360, 16)      16768     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68057 (265.85 KB)\n",
            "Trainable params: 67965 (265.49 KB)\n",
            "Non-trainable params: 92 (368.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "87/87 [==============================] - 121s 1s/step - loss: 0.2412 - val_loss: 0.6864 - lr: 0.0010\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_38 (ConvLSTM2D  (None, None, 122, 360,    30668     \n",
            " )                           17)                                 \n",
            "                                                                 \n",
            " batch_normalization_29 (Ba  (None, None, 122, 360,    68        \n",
            " tchNormalization)           17)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_39 (ConvLSTM2D  (None, None, 122, 360,    30844     \n",
            " )                           11)                                 \n",
            "                                                                 \n",
            " batch_normalization_30 (Ba  (None, None, 122, 360,    44        \n",
            " tchNormalization)           11)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_40 (ConvLSTM2D  (None, None, 122, 360,    5504      \n",
            " )                           8)                                  \n",
            "                                                                 \n",
            " batch_normalization_31 (Ba  (None, None, 122, 360,    32        \n",
            " tchNormalization)           8)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_41 (ConvLSTM2D  (None, None, 122, 360,    46872     \n",
            " )                           18)                                 \n",
            "                                                                 \n",
            " batch_normalization_32 (Ba  (None, None, 122, 360,    72        \n",
            " tchNormalization)           18)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_42 (ConvLSTM2D  (None, None, 122, 360,    54464     \n",
            " )                           16)                                 \n",
            "                                                                 \n",
            " batch_normalization_33 (Ba  (None, None, 122, 360,    64        \n",
            " tchNormalization)           16)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_43 (ConvLSTM2D  (None, 122, 360, 16)      18496     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 187273 (731.54 KB)\n",
            "Trainable params: 187133 (730.99 KB)\n",
            "Non-trainable params: 140 (560.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "173/173 [==============================] - 195s 1s/step - loss: 0.1553 - val_loss: 0.4509 - lr: 0.0100\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_44 (ConvLSTM2D  (None, None, 122, 360,    15648     \n",
            " )                           12)                                 \n",
            "                                                                 \n",
            " batch_normalization_34 (Ba  (None, None, 122, 360,    48        \n",
            " tchNormalization)           12)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_45 (ConvLSTM2D  (None, 122, 360, 16)      16192     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32033 (125.13 KB)\n",
            "Trainable params: 32009 (125.04 KB)\n",
            "Non-trainable params: 24 (96.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "139/139 [==============================] - 47s 298ms/step - loss: 0.0581 - val_loss: 0.0681 - lr: 0.0010\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_46 (ConvLSTM2D  (None, None, 122, 360,    9856      \n",
            " )                           16)                                 \n",
            "                                                                 \n",
            " batch_normalization_35 (Ba  (None, None, 122, 360,    64        \n",
            " tchNormalization)           16)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_47 (ConvLSTM2D  (None, None, 122, 360,    37752     \n",
            " )                           13)                                 \n",
            "                                                                 \n",
            " batch_normalization_36 (Ba  (None, None, 122, 360,    52        \n",
            " tchNormalization)           13)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_48 (ConvLSTM2D  (None, None, 122, 360,    71484     \n",
            " )                           21)                                 \n",
            "                                                                 \n",
            " batch_normalization_37 (Ba  (None, None, 122, 360,    84        \n",
            " tchNormalization)           21)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_49 (ConvLSTM2D  (None, 122, 360, 16)      21376     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140813 (550.05 KB)\n",
            "Trainable params: 140713 (549.66 KB)\n",
            "Non-trainable params: 100 (400.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "173/173 [==============================] - 139s 753ms/step - loss: 0.0952 - val_loss: 0.4391 - lr: 0.0100\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_50 (ConvLSTM2D  (None, None, 122, 360,    3276      \n",
            " )                           9)                                  \n",
            "                                                                 \n",
            " batch_normalization_38 (Ba  (None, None, 122, 360,    36        \n",
            " tchNormalization)           9)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_51 (ConvLSTM2D  (None, None, 122, 360,    19228     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_39 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_52 (ConvLSTM2D  (None, None, 122, 360,    25236     \n",
            " )                           9)                                  \n",
            "                                                                 \n",
            " batch_normalization_40 (Ba  (None, None, 122, 360,    36        \n",
            " tchNormalization)           9)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_53 (ConvLSTM2D  (None, 122, 360, 16)      14464     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62497 (244.13 KB)\n",
            "Trainable params: 62423 (243.84 KB)\n",
            "Non-trainable params: 74 (296.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "173/173 [==============================] - 100s 531ms/step - loss: 0.0353 - val_loss: 0.4025 - lr: 0.0010\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_54 (ConvLSTM2D  (None, None, 122, 360,    2624      \n",
            " )                           8)                                  \n",
            "                                                                 \n",
            " batch_normalization_41 (Ba  (None, None, 122, 360,    32        \n",
            " tchNormalization)           8)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_55 (ConvLSTM2D  (None, None, 122, 360,    23848     \n",
            " )                           22)                                 \n",
            "                                                                 \n",
            " batch_normalization_42 (Ba  (None, None, 122, 360,    88        \n",
            " tchNormalization)           22)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_56 (ConvLSTM2D  (None, None, 122, 360,    77976     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_43 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_57 (ConvLSTM2D  (None, None, 122, 360,    24048     \n",
            " )                           18)                                 \n",
            "                                                                 \n",
            " batch_normalization_44 (Ba  (None, None, 122, 360,    72        \n",
            " tchNormalization)           18)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_58 (ConvLSTM2D  (None, None, 122, 360,    25384     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_45 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_59 (ConvLSTM2D  (None, None, 122, 360,    9108      \n",
            " )                           9)                                  \n",
            "                                                                 \n",
            " batch_normalization_46 (Ba  (None, None, 122, 360,    36        \n",
            " tchNormalization)           9)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_60 (ConvLSTM2D  (None, 122, 360, 16)      14464     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 177977 (695.22 KB)\n",
            "Trainable params: 177787 (694.48 KB)\n",
            "Non-trainable params: 190 (760.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "346/346 [==============================] - 205s 543ms/step - loss: 0.0451 - val_loss: 0.3827 - lr: 0.0010\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_61 (ConvLSTM2D  (None, None, 122, 360,    5664      \n",
            " )                           12)                                 \n",
            "                                                                 \n",
            " batch_normalization_47 (Ba  (None, None, 122, 360,    48        \n",
            " tchNormalization)           12)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_62 (ConvLSTM2D  (None, None, 122, 360,    36456     \n",
            " )                           14)                                 \n",
            "                                                                 \n",
            " batch_normalization_48 (Ba  (None, None, 122, 360,    56        \n",
            " tchNormalization)           14)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_63 (ConvLSTM2D  (None, None, 122, 360,    68080     \n",
            " )                           20)                                 \n",
            "                                                                 \n",
            " batch_normalization_49 (Ba  (None, None, 122, 360,    80        \n",
            " tchNormalization)           20)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_64 (ConvLSTM2D  (None, None, 122, 360,    28880     \n",
            " )                           20)                                 \n",
            "                                                                 \n",
            " batch_normalization_50 (Ba  (None, None, 122, 360,    80        \n",
            " tchNormalization)           20)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_65 (ConvLSTM2D  (None, None, 122, 360,    22712     \n",
            " )                           17)                                 \n",
            "                                                                 \n",
            " batch_normalization_51 (Ba  (None, None, 122, 360,    68        \n",
            " tchNormalization)           17)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_66 (ConvLSTM2D  (None, None, 122, 360,    7232      \n",
            " )                           8)                                  \n",
            "                                                                 \n",
            " batch_normalization_52 (Ba  (None, None, 122, 360,    32        \n",
            " tchNormalization)           8)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_67 (ConvLSTM2D  (None, 122, 360, 16)      13888     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 183421 (716.49 KB)\n",
            "Trainable params: 183239 (715.78 KB)\n",
            "Non-trainable params: 182 (728.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "139/139 [==============================] - 204s 1s/step - loss: 0.6466 - val_loss: 0.6915 - lr: 0.0100\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_68 (ConvLSTM2D  (None, None, 122, 360,    30668     \n",
            " )                           17)                                 \n",
            "                                                                 \n",
            " batch_normalization_53 (Ba  (None, None, 122, 360,    68        \n",
            " tchNormalization)           17)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_69 (ConvLSTM2D  (None, None, 122, 360,    85888     \n",
            " )                           22)                                 \n",
            "                                                                 \n",
            " batch_normalization_54 (Ba  (None, None, 122, 360,    88        \n",
            " tchNormalization)           22)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_70 (ConvLSTM2D  (None, None, 122, 360,    24032     \n",
            " )                           8)                                  \n",
            "                                                                 \n",
            " batch_normalization_55 (Ba  (None, None, 122, 360,    32        \n",
            " tchNormalization)           8)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_71 (ConvLSTM2D  (None, None, 122, 360,    16920     \n",
            " )                           18)                                 \n",
            "                                                                 \n",
            " batch_normalization_56 (Ba  (None, None, 122, 360,    72        \n",
            " tchNormalization)           18)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_72 (ConvLSTM2D  (None, None, 122, 360,    81984     \n",
            " )                           21)                                 \n",
            "                                                                 \n",
            " batch_normalization_57 (Ba  (None, None, 122, 360,    84        \n",
            " tchNormalization)           21)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_73 (ConvLSTM2D  (None, None, 122, 360,    27436     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_58 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_74 (ConvLSTM2D  (None, 122, 360, 16)      20224     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 287717 (1.10 MB)\n",
            "Trainable params: 287507 (1.10 MB)\n",
            "Non-trainable params: 210 (840.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "139/139 [==============================] - 254s 2s/step - loss: 0.2840 - val_loss: 0.4543 - lr: 0.0100\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_75 (ConvLSTM2D  (None, None, 122, 360,    4000      \n",
            " )                           10)                                 \n",
            "                                                                 \n",
            " batch_normalization_59 (Ba  (None, None, 122, 360,    40        \n",
            " tchNormalization)           10)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_76 (ConvLSTM2D  (None, None, 122, 360,    17136     \n",
            " )                           9)                                  \n",
            "                                                                 \n",
            " batch_normalization_60 (Ba  (None, None, 122, 360,    36        \n",
            " tchNormalization)           9)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_77 (ConvLSTM2D  (None, None, 122, 360,    63084     \n",
            " )                           21)                                 \n",
            "                                                                 \n",
            " batch_normalization_61 (Ba  (None, None, 122, 360,    84        \n",
            " tchNormalization)           21)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_78 (ConvLSTM2D  (None, None, 122, 360,    17696     \n",
            " )                           14)                                 \n",
            "                                                                 \n",
            " batch_normalization_62 (Ba  (None, None, 122, 360,    56        \n",
            " tchNormalization)           14)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_79 (ConvLSTM2D  (None, None, 122, 360,    9944      \n",
            " )                           11)                                 \n",
            "                                                                 \n",
            " batch_normalization_63 (Ba  (None, None, 122, 360,    44        \n",
            " tchNormalization)           11)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_80 (ConvLSTM2D  (None, 122, 360, 16)      15616     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127881 (499.54 KB)\n",
            "Trainable params: 127751 (499.03 KB)\n",
            "Non-trainable params: 130 (520.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "346/346 [==============================] - 174s 462ms/step - loss: 0.0537 - val_loss: 0.5057 - lr: 0.0010\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_81 (ConvLSTM2D  (None, None, 122, 360,    46284     \n",
            " )                           21)                                 \n",
            "                                                                 \n",
            " batch_normalization_64 (Ba  (None, None, 122, 360,    84        \n",
            " tchNormalization)           21)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_82 (ConvLSTM2D  (None, None, 122, 360,    64668     \n",
            " )                           17)                                 \n",
            "                                                                 \n",
            " batch_normalization_65 (Ba  (None, None, 122, 360,    68        \n",
            " tchNormalization)           17)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_83 (ConvLSTM2D  (None, None, 122, 360,    68476     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_66 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_84 (ConvLSTM2D  (None, None, 122, 360,    37248     \n",
            " )                           12)                                 \n",
            "                                                                 \n",
            " batch_normalization_67 (Ba  (None, None, 122, 360,    48        \n",
            " tchNormalization)           12)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_85 (ConvLSTM2D  (None, None, 122, 360,    11752     \n",
            " )                           13)                                 \n",
            "                                                                 \n",
            " batch_normalization_68 (Ba  (None, None, 122, 360,    52        \n",
            " tchNormalization)           13)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_86 (ConvLSTM2D  (None, None, 122, 360,    60876     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_69 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_87 (ConvLSTM2D  (None, 122, 360, 16)      20224     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 310077 (1.18 MB)\n",
            "Trainable params: 309875 (1.18 MB)\n",
            "Non-trainable params: 202 (808.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "139/139 [==============================] - 265s 2s/step - loss: 0.0441 - val_loss: 0.4464 - lr: 0.0010\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_88 (ConvLSTM2D  (None, None, 122, 360,    5664      \n",
            " )                           12)                                 \n",
            "                                                                 \n",
            " batch_normalization_70 (Ba  (None, None, 122, 360,    48        \n",
            " tchNormalization)           12)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_89 (ConvLSTM2D  (None, None, 122, 360,    58976     \n",
            " )                           19)                                 \n",
            "                                                                 \n",
            " batch_normalization_71 (Ba  (None, None, 122, 360,    76        \n",
            " tchNormalization)           19)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_90 (ConvLSTM2D  (None, 122, 360, 16)      20224     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85133 (332.55 KB)\n",
            "Trainable params: 85071 (332.31 KB)\n",
            "Non-trainable params: 62 (248.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "87/87 [==============================] - 82s 835ms/step - loss: 0.0636 - val_loss: 0.4307 - lr: 0.0010\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_91 (ConvLSTM2D  (None, None, 122, 360,    34272     \n",
            " )                           18)                                 \n",
            "                                                                 \n",
            " batch_normalization_72 (Ba  (None, None, 122, 360,    72        \n",
            " tchNormalization)           18)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_92 (ConvLSTM2D  (None, None, 122, 360,    11528     \n",
            " )                           11)                                 \n",
            "                                                                 \n",
            " batch_normalization_73 (Ba  (None, None, 122, 360,    44        \n",
            " tchNormalization)           11)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_93 (ConvLSTM2D  (None, None, 122, 360,    5504      \n",
            " )                           8)                                  \n",
            "                                                                 \n",
            " batch_normalization_74 (Ba  (None, None, 122, 360,    32        \n",
            " tchNormalization)           8)                                  \n",
            "                                                                 \n",
            " conv_lstm2d_94 (ConvLSTM2D  (None, None, 122, 360,    11144     \n",
            " )                           14)                                 \n",
            "                                                                 \n",
            " batch_normalization_75 (Ba  (None, None, 122, 360,    56        \n",
            " tchNormalization)           14)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_95 (ConvLSTM2D  (None, None, 122, 360,    73584     \n",
            " )                           21)                                 \n",
            "                                                                 \n",
            " batch_normalization_76 (Ba  (None, None, 122, 360,    84        \n",
            " tchNormalization)           21)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_96 (ConvLSTM2D  (None, None, 122, 360,    14304     \n",
            " )                           12)                                 \n",
            "                                                                 \n",
            " batch_normalization_77 (Ba  (None, None, 122, 360,    48        \n",
            " tchNormalization)           12)                                 \n",
            "                                                                 \n",
            " conv_lstm2d_97 (ConvLSTM2D  (None, 122, 360, 16)      16192     \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 122, 360, 1)       145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167009 (652.38 KB)\n",
            "Trainable params: 166841 (651.72 KB)\n",
            "Non-trainable params: 168 (672.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "139/139 [==============================] - 197s 1s/step - loss: 0.0894 - val_loss: 0.4893 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hof_decoded = [decodificar_ind(ind.chrom) for ind in hof]\n",
        "\n",
        "hof_decoded"
      ],
      "metadata": {
        "id": "j7ur2n5G9E02",
        "outputId": "75955e3f-6a7f-4ba0-c4ed-22eaf04cd082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'loss': 'mae',\n",
              "  'batch_size': 5,\n",
              "  'optimizer': 'adam',\n",
              "  'n_modulos': 1,\n",
              "  'modulos': [{'kernel': (5, 5),\n",
              "    'filters': 12,\n",
              "    'dropout': 0.47,\n",
              "    'recurrent_dropout': 0.809}]},\n",
              " {'loss': 'mae',\n",
              "  'batch_size': 8,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'n_modulos': 1,\n",
              "  'modulos': [{'kernel': (5, 5),\n",
              "    'filters': 16,\n",
              "    'dropout': 0.28,\n",
              "    'recurrent_dropout': 0.602}]},\n",
              " {'loss': 'mae',\n",
              "  'batch_size': 2,\n",
              "  'optimizer': 'adam',\n",
              "  'n_modulos': 6,\n",
              "  'modulos': [{'kernel': (3, 3),\n",
              "    'filters': 8,\n",
              "    'dropout': 0.3,\n",
              "    'recurrent_dropout': 0.41},\n",
              "   {'kernel': (3, 3),\n",
              "    'filters': 22,\n",
              "    'dropout': 0.002,\n",
              "    'recurrent_dropout': 0.069},\n",
              "   {'kernel': (5, 5),\n",
              "    'filters': 19,\n",
              "    'dropout': 0.527,\n",
              "    'recurrent_dropout': 0.0},\n",
              "   {'kernel': (3, 3),\n",
              "    'filters': 18,\n",
              "    'dropout': 0.754,\n",
              "    'recurrent_dropout': 0.052},\n",
              "   {'kernel': (3, 3),\n",
              "    'filters': 19,\n",
              "    'dropout': 0.001,\n",
              "    'recurrent_dropout': 0.07},\n",
              "   {'kernel': (3, 3),\n",
              "    'filters': 9,\n",
              "    'dropout': 0.905,\n",
              "    'recurrent_dropout': 0.19}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FdI5nfdM9w_b"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YNr4xFjnGHRJ",
        "-PlAdLYpCipv"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}